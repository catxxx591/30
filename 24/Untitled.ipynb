{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/AT\n",
      "  Fulton/NP-TL\n",
      "  County/NN-TL\n",
      "  Grand/JJ-TL\n",
      "  Jury/NN-TL\n",
      "  said/VBD\n",
      "  Friday/NR\n",
      "  an/AT\n",
      "  investigation/NN\n",
      "  of/IN\n",
      "  Atlanta's/NP$\n",
      "  recent/JJ\n",
      "  primary/NN\n",
      "  election/NN\n",
      "  produced/VBD\n",
      "  ``/``\n",
      "  no/AT\n",
      "  evidence/NN\n",
      "  ''/''\n",
      "  that/CS\n",
      "  any/DTI\n",
      "  irregularities/NNS\n",
      "  took/VBD\n",
      "  place/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "cp = nltk.RegexpParser( 'CHUNK: {<V.*> <TO> <V.*>}' )\n",
    "brown = nltk.corpus.brown\n",
    "for sent in brown.tagged_sents() :\n",
    "    tree = cp.parse(sent)\n",
    "\n",
    "    for subtree in tree.subtrees():\n",
    "        print(subtree)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from nltk.corpus import conll2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> test_sents = conll2000.chunked_sents('test.txt', chunk_types=['NP'])\n",
    ">>> train_sents = conll2000.chunked_sents('train.txt', chunk_types=['NP'])\n",
    ">>> unigram_chunker = UnigramChunker(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.UnigramChunker at 0x2200e4e4cf8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Confidence', 'NN', 'B-NP'), ('in', 'IN', 'O'), ('the', 'DT', 'B-NP'), ('pound', 'NN', 'I-NP'), ('is', 'VBZ', 'O'), ('widely', 'RB', 'O'), ('expected', 'VBN', 'O'), ('to', 'TO', 'O'), ('take', 'VB', 'O'), ('another', 'DT', 'B-NP'), ('sharp', 'JJ', 'I-NP'), ('dive', 'NN', 'I-NP'), ('if', 'IN', 'O'), ('trade', 'NN', 'B-NP'), ('figures', 'NNS', 'I-NP'), ('for', 'IN', 'O'), ('September', 'NNP', 'B-NP'), (',', ',', 'O'), ('due', 'JJ', 'O'), ('for', 'IN', 'O'), ('release', 'NN', 'B-NP'), ('tomorrow', 'NN', 'B-NP'), (',', ',', 'O'), ('fail', 'VB', 'O'), ('to', 'TO', 'O'), ('show', 'VB', 'O'), ('a', 'DT', 'B-NP'), ('substantial', 'JJ', 'I-NP'), ('improvement', 'NN', 'I-NP'), ('from', 'IN', 'O'), ('July', 'NNP', 'B-NP'), ('and', 'CC', 'I-NP'), ('August', 'NNP', 'I-NP'), (\"'s\", 'POS', 'B-NP'), ('near-record', 'JJ', 'I-NP'), ('deficits', 'NNS', 'I-NP'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "for sent in train_sents:\n",
    "    print(nltk.chunk.tree2conlltags(sent))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents): \n",
    "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]\n",
    "                      for sent in train_sents]\n",
    "        self.tagger = nltk.UnigramTagger(train_data) \n",
    "\n",
    "        \n",
    "\n",
    "    def parse(self, sentence): \n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
    "                     in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_chunker = UnigramChunker(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2=[]\n",
    "for sent in train_sents:\n",
    "    a = []\n",
    "    for w,t,c in nltk.chunk.tree2conlltags(sent):\n",
    "        a.append((t,c))\n",
    "    train_data2.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data2[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Confidence', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('pound', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('widely', 'RB'),\n",
       " ('expected', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('take', 'VB'),\n",
       " ('another', 'DT'),\n",
       " ('sharp', 'JJ'),\n",
       " ('dive', 'NN'),\n",
       " ('if', 'IN'),\n",
       " ('trade', 'NN'),\n",
       " ('figures', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('September', 'NNP'),\n",
       " (',', ','),\n",
       " ('due', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('release', 'NN'),\n",
       " ('tomorrow', 'NN'),\n",
       " (',', ','),\n",
       " ('fail', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('show', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('substantial', 'JJ'),\n",
       " ('improvement', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('July', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('August', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('near-record', 'JJ'),\n",
       " ('deficits', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.leaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<UnigramTagger: size=44>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.UnigramTagger(train_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "postags = sorted(set(pos #for sent in train_sents\n",
    "                      for (word,pos) in sent.leaves()for sent in train_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('S', [Tree('NP', [('Confidence', 'NN')]), ('in', 'IN'), Tree('NP', [('the', 'DT'), ('pound', 'NN')]), ('is', 'VBZ'), ('widely', 'RB'), ('expected', 'VBN'), ('to', 'TO'), ('take', 'VB'), Tree('NP', [('another', 'DT'), ('sharp', 'JJ'), ('dive', 'NN')]), ('if', 'IN'), Tree('NP', [('trade', 'NN'), ('figures', 'NNS')]), ('for', 'IN'), Tree('NP', [('September', 'NNP')]), (',', ','), ('due', 'JJ'), ('for', 'IN'), Tree('NP', [('release', 'NN')]), Tree('NP', [('tomorrow', 'NN')]), (',', ','), ('fail', 'VB'), ('to', 'TO'), ('show', 'VB'), Tree('NP', [('a', 'DT'), ('substantial', 'JJ'), ('improvement', 'NN')]), ('from', 'IN'), Tree('NP', [('July', 'NNP'), ('and', 'CC'), ('August', 'NNP')]), Tree('NP', [(\"'s\", 'POS'), ('near-record', 'JJ'), ('deficits', 'NNS')]), ('.', '.')]), Tree('S', [('Chancellor', 'NNP'), ('of', 'IN'), Tree('NP', [('the', 'DT'), ('Exchequer', 'NNP')]), Tree('NP', [('Nigel', 'NNP'), ('Lawson', 'NNP')]), Tree('NP', [(\"'s\", 'POS'), ('restated', 'VBN'), ('commitment', 'NN')]), ('to', 'TO'), Tree('NP', [('a', 'DT'), ('firm', 'NN'), ('monetary', 'JJ'), ('policy', 'NN')]), ('has', 'VBZ'), ('helped', 'VBN'), ('to', 'TO'), ('prevent', 'VB'), Tree('NP', [('a', 'DT'), ('freefall', 'NN')]), ('in', 'IN'), Tree('NP', [('sterling', 'NN')]), ('over', 'IN'), Tree('NP', [('the', 'DT'), ('past', 'JJ'), ('week', 'NN')]), ('.', '.')]), ...]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 'O'), ('.', 'O'), ('CC', 'O'), ('DT', 'B-NP'), ('IN', 'O'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('NNP', 'I-NP'), ('NNS', 'I-NP'), ('POS', 'B-NP'), ('RB', 'O'), ('TO', 'O'), ('VB', 'O'), ('VBN', 'O'), ('VBZ', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print (unigram_chunker.tagger.tag(postags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#',\n",
       " '$',\n",
       " \"''\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '.',\n",
       " ':',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'DT',\n",
       " 'EX',\n",
       " 'FW',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'MD',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNPS',\n",
       " 'NNS',\n",
       " 'PDT',\n",
       " 'POS',\n",
       " 'PRP',\n",
       " 'PRP$',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'RP',\n",
       " 'SYM',\n",
       " 'TO',\n",
       " 'UH',\n",
       " 'VB',\n",
       " 'VBD',\n",
       " 'VBG',\n",
       " 'VBN',\n",
       " 'VBP',\n",
       " 'VBZ',\n",
       " 'WDT',\n",
       " 'WP',\n",
       " 'WP$',\n",
       " 'WRB',\n",
       " '``']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('in', 'IN')\n"
     ]
    }
   ],
   "source": [
    "for sent in train_sents:\n",
    "    print(sent)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
