評估模型
==
為了決定一個分類模型是否準確地捕捉了模式，我們必須評估該模型。評估的結果對於決定模型是多麼值得信賴以及我們如何使用它是非常重要。評估也可以是一個有效的工具，用於指導我們在未來改進模型。

- 測試集
1. 注意少數標籤的數量
對於有少量平衡的標籤和一個多樣化的測試集的分類任務，只要100個評估實例就可以進行有意義的評估。
但是，如果一個分類任務有大量的標籤或包括非常罕見的標籤，那麼選擇的測試集的大小就要保證出現次數最少的標籤至少出現50次。

2. 確保測試集獨立
如果測試集中出現來自於訓練集的資料，將高估模型的精度

3. 注意樣本多樣性
測試集與訓練集的數據越相似輸出的精度就越可能被高估，也許模型只適合使用在這種類型的資料，例如評估東方股市指標的模型使用西方股市資料測試精度往往降低，因為訓練模型時就沒碰過西方數據

- 準確度
解釋一個分類器的準確性得分，考慮測試集中單個類標籤的頻率是很重要的。
我們在以色列判斷阿明95%是猶太人比起在美國判斷阿明95%是猶太人，一樣是95%但積極程度是不一樣的

- 精確度和召回率

我們給出一個一定會出現以下其中一種結果
![](https://github.com/catxxx591/30/blob/master/img/ABF.jpg?raw=true)

因此，對搜索任務使用不同的測量集是很常見的，基於上圖所示的四個類別的每一個中的項目的數量：

真陽性是相關項目中我們正確識別為相關的。
真陰性是不相關項目中我們正確識別為不相關的。
假陽性（或I型錯誤）是不相關項目中我們錯誤識別為相關的。
假陰性（或II型錯誤）是相關項目中我們錯誤識別為不相關的。
給定這四個數字，我們可以定義以下指標：

精確度，表示我們發現的項目中有多少是相關的，TP/(TP+FP)。
召回率，表示相關的項目中我們發現了多少，TP/(TP+FN)。
F-度量值（或F-Score），組合精確度和召回率為一個單獨的得分，被定義為精確度和召回率的調和平均數(2 × Precision × Recall ) / ( Precision + Recall )。

- 混淆矩陣
當處理有3個或更多的標籤的分類任務時，基於模型錯誤類型細分模型的錯誤是有信息量的。一個混淆矩陣是一個表，其中每個cells [ i , j ]表示正確的標籤i被預測為標籤j的次數。因此，對角線項目（即cells |ii|）表示正確預測的標籤，非對角線項目表示錯誤。在下面的例子中，我們為4中開發的一元標註器生成一個混淆矩陣：

```
     | N | | NIAJNVN | | NNTJ . S , BP | 
----+------------- -------------------------------------------------- -+ 
NN | <11.8%> 0.0% . 0.2% . 0.0% . 0.3% 0.0% | 
IN | 0.0% <9.0%> . . . 0.0% . . . | 
AT | . . <8.6%> . . . . . . | 
JJ | 1.7% . . <3.9%> . . . 0.0% 0.0% | 
  . | . . . . <4.8%> . . . . |
NNS | 1.5% . . . . <3.2%> . . 0.0% | 
  , | . . . . . . <4.4%> . . | 
VB | 0.9% . . 0.0% . . . <2.4%> . | 
NP | 1.0% . . 0.0% . . . . <1.8%>| 
----+----------------------------- -----------------------------------+ 
(row = reference; col = test)
```

- 交叉驗證
我們在使用太小的測試集測試模型時評價會不準確，但當測試集佔特徵集比例越大往往表示訓練集被縮小了。我們可以將現有的測試集分為N份，將這些測試集都去測試模型會得到N個評分，當這N個分數彼此相近差異不大那麼這個模型是較可信賴的。另一方面，如果N個訓練集上分數很大不同，那麼，我們應該對評估得分的準確性持懷疑態度。

- 決策樹

決策樹是一個簡單的為輸入值選擇標籤的流程圖。這個流程圖由檢查特徵值的決策節點和分配標籤的葉節點組成。為輸入值選擇標籤，我們以流程圖的初始決策節點開始，稱為其根節點。此節點包含一個條件，檢查輸入值的特徵之一，基於該特徵的值選擇一個分支。沿著這個描述我們輸入值的分支，我們到達了一個新的決策節點，有一個關於輸入值的特徵的新的條件。我們繼續沿著每個節點的條件選擇的分支，直到到達葉節點，它為輸入值提供了一個標籤。
![](https://github.com/catxxx591/30/blob/master/img/dtree_sample.jpg?raw=true)
一旦我們選擇了一個特徵，就可以通過分配一個標籤給每個葉子，基於在訓練集中所選的例子的最頻繁的標籤，建立決策樹樁（即選擇特徵具有那個值的例子）。

- 熵和信息增益
正如之前提到的，有幾種方法來為決策樹樁確定最有信息量的特徵。一種流行的替代方法，被稱為信息增益，當我們用給定的特徵分割輸入值時，衡量它們變得更有序的程度。要衡量原始輸入值集合如何無序，我們計算它們的標籤的墒，如果輸入值的標籤非常不同，墒就高；如果輸入值的標籤都相同，墒就低。特別地，熵被定義為每個標籤的概率乘以那個標籤的log概率的總和：

